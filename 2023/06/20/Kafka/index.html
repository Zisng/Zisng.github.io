


<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,inital-scale=1,user-scalable=no">
  <title>Kafka [ Hexo ]</title>
  <!-- bootstrapcss文件 -->
 <!--  <link rel="stylesheet" href="https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"> -->
<!--   
<link rel="stylesheet" href="css/zhl.css">

 -->
  
    <!-- stylesheets list from config.yml -->
    
      <link rel="stylesheet" href="/css/fork-awesome.min.css">
    
      <link rel="stylesheet" href="/css/zhl.css">
    
  
  
<meta name="generator" content="Hexo 6.3.0"></head>
<body>
<div class="container-fluid">
  <div class="row">
  <div id="wrap" class="col-md-12">
    <div id="header">
	<div id="header-left">
	<h1 id="header-title"> 
	<a href="/">
		Hexo
	</a>
	</h1>
	
	</div>
	<div id="header-right">
		
		
		<a href="/"  title="home"><i class="fa fa-home ">home</i></a>
		
		<a target="_blank" rel="noopener" href="https://github.com/lizehongss/demo_show"  title="demo"><i class="fa fa-code ">demo</i></a>
		
		<a href="/about"  title="about"><i class="fa fa-user ">about</i></a>
		
		<a href="/"  title="music"><i class="fa fa-music ">music</i></a>
		
		
	</div>
</div>

  </div>
  </div>
  <div id="content" class="row">
    <div id="content-left" class="col-md-4">
      

	

	

	
	<div class="widget-wrap">
		<h3 class="widget-title fa fa-archive">归档</h3>
		<div class="widget">
			<ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="archives/2023/">2023</a><span class="archive-list-count">12</span></li></ul>
		</div>
	</div>



    </div>
    <div id="content-right" class="col-md-8">
    
<article id="post">
	<div class="post-title">
  <h1>Kafka</h1>
  	</div>
  <div class="page-meta">
  	<span class="fa-wrap">
  		<i class="fa fa-clock-o"></i>
  		<span class="date-meta">2023-06-20</span>
  	</span>
  	<span class="fa-wrap">
  		
  	</span>
  	<span class="fa-wrap">
  		
  	</span>
  </div>
  <div class="post-content">
  <p>（一）安装kafka集群</p>
<p>1.需要的环境有：java和zookeeper</p>
<p>2.移动包到/export/server</p>
<img src="/2023/06/20/Kafka/clip_image002.jpg" class="" title="img">
<p>3.解压并设置软连接</p>
<p>tar zxvf kafka_2.11-2.0.0.tgz</p>
<img src="/2023/06/20/Kafka/clip_image004.jpg" class="" title="img">
<img src="/2023/06/20/Kafka/clip_image006.jpg" class="" title="img">
<p>4.修改配置文件</p>
<p>（1）vim /etc/profile</p>
<img src="/2023/06/20/Kafka/clip_image008.jpg" class="" title="img">
<p>（2）cd /export/server/kafka/config</p>
<p>vi server.properties</p>
<p>#为依次增长的:0、1、2、3、4,集群中唯一 id --》从0开始，每台不能重复，第一块要改的</p>
<p>broker.id=0</p>
<p>----Logbasic------</p>
<p>#数据存储的目录，第二块要改的</p>
<p>log.dirs=/export/data/kafka-logs</p>
<p>—zookeeper----</p>
<p>#指定 zk 集群地址，第四块要改的</p>
<p>zookeeper.connect=node1:2181,node2:2181,node3:2181</p>
<img src="/2023/06/20/Kafka/clip_image010.jpg" class="" title="img">
<p>\5. 分发kafka</p>
<p>scp -r kafka root@node2:/export/server/</p>
<p>scp -r kafka root@node3:/export/server/</p>
<img src="/2023/06/20/Kafka/clip_image012.jpg" class="" title="img">
<p>\6. 分别在node2和node3上修改配置文件</p>
<img src="/2023/06/20/Kafka/clip_image014.jpg" class="" title="img">
<p>node2上的broker.id改成1，node3上的broker.id改成2</p>
<p>7.启动kafka集群</p>
<p><a target="_blank" rel="noopener" href="http://kafka-server-start.sh">kafka-server-start.sh</a> -daemon /export/server/kafka/config/server.properties（三个节点都启动）</p>
<img src="/2023/06/20/Kafka/clip_image016.jpg" class="" title="img">
<p>8.一键启停脚本</p>
<p>#!/bin/bash</p>
<p>if [ $# -eq 0 ]</p>
<p>then</p>
<p>​    echo “please input param:start stop”</p>
<p>else</p>
<p>​    if [ $1 = start ]</p>
<p>​       then</p>
<p>​           for i in {1…3}</p>
<p>​           do</p>
<p>​              echo “${1}ing node${i}”</p>
<p>​              ssh node${i} “source /etc/profile;/export/server/kafka/bin/kafka-server-start.sh -daemon /export/server/kafka/config/server.properties”</p>
<p>​           done</p>
<p>​    fi</p>
<p>​    if [ $1 = stop ]</p>
<p>​       then</p>
<p>​           for i in {1…3}</p>
<p>​           do</p>
<p>​               echo “${1}ing node${i}”</p>
<p>​              ssh node${i} “source       /etc/profile;/export/server/kafka/bin/kafka-server-stop.sh”</p>
<p>​           done</p>
<p>​    fi</p>
<p>​    if [ $1 = status ]</p>
<p>​       then</p>
<p>​           for i in {1…3}</p>
<p>​           do</p>
<p>​              echo “node${i} status:”</p>
<p>​              ssh node${i} “source /etc/profile;/export/server/kafka/bin/kafka-server-status.sh”</p>
<p>​           done</p>
<p>​    fi</p>
<p>fi</p>
<img src="/2023/06/20/Kafka/clip_image018.jpg" class="" title="img">
<p>（二）kafka操作</p>
<p>1.创建topic</p>
<p>（1）基本方式</p>
<p>./kafka-topics.sh --create --topic tpc_1 --partitions 2 --replication-factor 2 --zookeeper node1:2181</p>
<img src="/2023/06/20/Kafka/clip_image020.jpg" class="" title="img">
<p>（2）手动指定副本的存储位置</p>
<p>bin/kafka-topics.sh --create --topic tpc_2 --zookeeper node1:2181 --replica-assignment 0:1,1:2</p>
<img src="/2023/06/20/Kafka/clip_image022.jpg" class="" title="img">
<p>（3） 创建名为test的主题</p>
<p>./kafka-topics.sh --zookeeper localhost:2181 --create --topic test --replication-factor 1 --partitions 5</p>
<img src="/2023/06/20/Kafka/clip_image024.jpg" class="" title="img">
<p>2）查看主题</p>
<p>./kafka-topics.sh --zookeeper node1:2181 –list</p>
<img src="/2023/06/20/Kafka/clip_image026.jpg" class="" title="img">
<p>2.删除topic</p>
<p>bin/kafka-topics.sh --delete --topic tpc_1 --zookeeper node1:2181</p>
<img src="/2023/06/20/Kafka/clip_image028.jpg" class="" title="img">
<p>\3. 查看topic</p>
<p>（1）列出当前系统中的所有 topic</p>
<p>bin/kafka-topics.sh --zookeeper node1:2181,node2:2181,node3:2181 –list</p>
<img src="/2023/06/20/Kafka/clip_image030.jpg" class="" title="img">
<p>（2）查看 topic 详细信息</p>
<p>bin/kafka-topics.sh --describe --topic tpc_1 --zookeeper node1:2181</p>
<p><img src="kafka/clip_image032.jpg" alt="img"> <img src="kafka/clip_image033.jpg" alt="img"></p>
<p>\4. 增加分区数</p>
<p>bin/kafka-topics.sh --alter --topic tpc_1 --partitions 3 --zookeeper node1:2181</p>
<img src="/2023/06/20/Kafka/clip_image035.jpg" class="" title="img">
<p>\5. 动态配置topic 参数</p>
<p>（1）添加</p>
<p>bin/kafka-configs.sh --zookeeper node1:2181 --entity-type topics --entity-name tpc_1 --alter --add-config compression.type=gzip</p>
<img src="/2023/06/20/Kafka/clip_image037.jpg" class="" title="img">
<p>（2）删除配置参数</p>
<p>bin/kafka-configs.sh --zookeeper node1:2181 --entity-type topics --entity-name tpc_1 --alter --delete-config compression.type</p>
<img src="/2023/06/20/Kafka/clip_image039.jpg" class="" title="img">
<p>\6. 生产消息到Kafka并进行消费</p>
<p>bin/kafka-console-producer.sh --broker-list node1:9092, node2:9092, node3:9092 --topic tpc_1</p>
<img src="/2023/06/20/Kafka/clip_image041.jpg" class="" title="img">
<p>消费消息</p>
<p>bin/kafka-console-consumer.sh --bootstrap-server node1:9092, node2:9092, node1:9092 --topic tpc_1 --from-beginning</p>
<img src="/2023/06/20/Kafka/clip_image043.jpg" class="" title="img">
<p>\7. 配置管理kafka-configs</p>
<p>添加topic级别参数</p>
<p>bin/kafka-configs.sh --zookeeper node1:2181 --alter --entity-type topics --entity-name tpc_2 --add-config cleanup.policy=compact , max.message.bytes=10000</p>
<img src="/2023/06/20/Kafka/clip_image045.jpg" class="" title="img">
<p>8.kafka的生产者、消费者工具</p>
<img src="/2023/06/20/Kafka/clip_image047.jpg" class="" title="img">
<p>（三）Kafka Java API开发</p>
<p>1.producer生产者</p>
<p>（1）引入 maven 依赖</p>
<?xml version="1.0" encoding="UTF-8"?>
<p>&lt;project xmlns=“<a target="_blank" rel="noopener" href="http://maven.apache.org/POM/4.0.0">http://maven.apache.org/POM/4.0.0</a>”</p>
<p>​     xmlns:xsi=“<a target="_blank" rel="noopener" href="http://www.w3.org/2001/XMLSchema-instance">http://www.w3.org/2001/XMLSchema-instance</a>”</p>
<p>​     xsi:schemaLocation=“<a target="_blank" rel="noopener" href="http://maven.apache.org/POM/4.0.0">http://maven.apache.org/POM/4.0.0</a> <a target="_blank" rel="noopener" href="http://maven.apache.org/xsd/maven-4.0.0.xsd">http://maven.apache.org/xsd/maven-4.0.0.xsd</a>”&gt;</p>
<p><modelVersion>4.0.0</modelVersion></p>
<p><groupId>org.example</groupId></p>
<p><artifactId>rgzn_kafka</artifactId></p>
<p><version>1.0-SNAPSHOT</version></p>
  <dependencies>
<p>​    <dependency></p>
<p>​      <groupId>org.apache.kafka</groupId></p>
<p>​      <artifactId>kafka-clients</artifactId></p>
<p>​      <version>2.0.0</version></p>
<p>​    </dependency></p>
<p>​    <dependency></p>
<p>​      <groupId>org.apache.kafka</groupId></p>
<p>​      <artifactId>kafka_2.11</artifactId></p>
<p>​      <version>2.2.0</version></p>
<p>​    </dependency></p>
<p>​    <dependency></p>
<p>​      <groupId>org.slf4j</groupId></p>
<p>​      <artifactId>slf4j-simple</artifactId></p>
<p>​      <version>1.7.25</version></p>
<p>​      <scope>compile</scope></p>
<p>​    </dependency></p>
<p>​    <dependency></p>
<p>​      <groupId>org.apache.commons</groupId></p>
<p>​      <artifactId>commons-lang3</artifactId></p>
<p>​      <version>3.10</version></p>
<p>​    </dependency></p>
<p>​    <dependency></p>
<p>​      <groupId>org.apache.flume</groupId></p>
<p>​      <artifactId>flume-ng-core</artifactId></p>
<p>​      <version>1.9.0</version></p>
<p>​    </dependency></p>
<p>​    <!-- https://mvnrepository.com/artifact/redis.clients/jedis --></p>
<p>​    <dependency></p>
<p>​      <groupId>redis.clients</groupId></p>
<p>​      <artifactId>jedis</artifactId></p>
<p>​      <version>3.3.0</version></p>
<p>​    </dependency></p>
<p>​    <dependency></p>
<p>​      <groupId>junit</groupId></p>
<p>​      <artifactId>junit</artifactId></p>
<p>​      <version>4.12</version></p>
<p>​      <scope>compile</scope></p>
<p>​    </dependency></p>
  </dependencies>
  <repositories>
<p>​    <repository></p>
<p>​      <id>nexus-aliyun</id></p>
<p>​       <name>Nexus aliyun</name></p>
<p>​      <layout>default</layout></p>
<p>​       <url><a target="_blank" rel="noopener" href="http://maven.aliyun.com/nexus/content/groups/public">http://maven.aliyun.com/nexus/content/groups/public</a></url></p>
<p>​      <snapshots></p>
<p>​        <enabled>false</enabled></p>
<p>​        <updatePolicy>never</updatePolicy></p>
<p>​      </snapshots></p>
<p>​      <releases></p>
<p>​        <enabled>true</enabled></p>
<p>​        <updatePolicy>never</updatePolicy></p>
<p>​      </releases></p>
<p>​    </repository></p>
  </repositories>
  <pluginRepositories>
<p>​    <pluginRepository></p>
<p>​      <id>ali-plugin</id></p>
<p>​      <url><a target="_blank" rel="noopener" href="http://maven.aliyun.com/nexus/content/groups/public/">http://maven.aliyun.com/nexus/content/groups/public/</a></url></p>
<p>​      <snapshots></p>
<p>​        <enabled>false</enabled></p>
<p>​        <updatePolicy>never</updatePolicy></p>
<p>​      </snapshots></p>
<p>​      <releases></p>
<p>​        <enabled>true</enabled></p>
<p>​        <updatePolicy>never</updatePolicy></p>
<p>​      </releases></p>
<p>​    </pluginRepository></p>
  </pluginRepositories>
  <build>
<p>​    <plugins></p>
<p>​      <!-- 指定编译java的插件 --></p>
<p>​      <plugin></p>
<p>​        <groupId>org.apache.maven.plugins</groupId></p>
<p>​        <artifactId>maven-compiler-plugin</artifactId></p>
<p>​        <version>3.5.1</version></p>
<p>​        <configuration></p>
<p>​          <source>1.8</source></p>
<p>​          <target>1.8</target></p>
<p>​        </configuration></p>
<p>​      </plugin></p>
<p>​      <!-- 指定编译scala的插件 --></p>
<p>​      <plugin></p>
<p>​        <groupId>net.alchim31.maven</groupId></p>
<p>​        <artifactId>scala-maven-plugin</artifactId></p>
<p>​        <version>3.2.2</version></p>
<p>​        <executions></p>
<p>​          <execution></p>
<p>​            <goals></p>
<p>​              <goal>compile</goal></p>
<p>​              <goal>testCompile</goal></p>
<p>​            </goals></p>
<p>​            <configuration></p>
<p>​              <args></p>
<p>​                <arg>-dependencyfile</arg></p>
<p>​                <arg>${project.build.directory}/.scala_dependencies</arg></p>
<p>​              </args></p>
<p>​            </configuration></p>
<p>​          </execution></p>
<p>​        </executions></p>
<p>​      </plugin></p>
<p>​      <!-- 把依赖jar中的用到的类，提取到自己的jar中 --></p>
<p>​      <plugin></p>
<p>​        <groupId>org.apache.maven.plugins</groupId></p>
<p>​        <artifactId>maven-assembly-plugin</artifactId></p>
<p>​        <version>2.6</version></p>
<p>​        <configuration></p>
<p>​          <archive></p>
<p>​            <manifest></p>
<p>​              <mainClass>cn.doitedu.loggen.entry.GenAppLog</mainClass></p>
<p>​            </manifest></p>
<p>​          </archive></p>
<p>​          <descriptorRefs></p>
<p>​            <descriptorRef>jar-with-dependencies</descriptorRef></p>
<p>​          </descriptorRefs></p>
<p>​        </configuration></p>
<p>​        <!--下面是为了使用 mvn package命令，如果不加则使用mvn assembly--></p>
<p>​        <executions></p>
<p>​          <execution></p>
<p>​            <id>make-assemble</id></p>
<p>​            <phase>package</phase></p>
<p>​            <goals></p>
<p>​              <goal>single</goal></p>
<p>​            </goals></p>
<p>​          </execution></p>
<p>​        </executions></p>
<p>​      </plugin></p>
<p>​    </plugins></p>
  </build>
</project>
<img src="/2023/06/20/Kafka/clip_image049.jpg" class="" title="img">
<p>（2）运行代码</p>
<img src="/2023/06/20/Kafka/clip_image051.jpg" class="" title="img">
<p>2.consumer生产者</p>
<p>（1）运行以下代码</p>
<p>package ccjz;</p>
<p>/**</p>
<p>* @BelongsProject: kafka-group</p>
<p>* @BelongsPackage: ccjz</p>
<p>* @CreateTime: 2023-05-28 14:47</p>
<p>* @Description: TODO</p>
<p>* @Version: 1.0</p>
<p>*/</p>
<p>import org.apache.kafka.clients.consumer.*;</p>
<p>import org.apache.kafka.common.TopicPartition;</p>
<p>import org.apache.kafka.common.serialization.StringDeserializer;</p>
<p>import java.time.Duration;</p>
<p>import java.util.Arrays;</p>
<p>import java.util.Collection;</p>
<p>import java.util.Properties;</p>
<p>import java.util.Set;</p>
<p>public class ConsumerSeekOffset {</p>
<p>public static void main(String[] args) {</p>
<p>​    Properties props = new Properties();</p>
<p>​    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</p>
<p>props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,“node1:9092,node2:9092,node3:9092”);</p>
<p>​    props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,“earliest”);</p>
<p>​    props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,true);</p>
<p>​    props.put(ConsumerConfig.GROUP_ID_CONFIG,“g1”);</p>
<p>​    //创建kafka实例对象</p>
<p>​    KafkaConsumer&lt;String, String&gt; kafkaConsumer = new KafkaConsumer&lt;String, String&gt;(props);</p>
<p>​    //订阅主题</p>
<p>​    kafkaConsumer.subscribe(Arrays.asList(“tpc_1”));</p>
<p>​    //先拉取一次消息</p>
<p>​    kafkaConsumer.poll(Duration.ofMillis(10000));</p>
<p>​    //先看看被分配了哪些topic中的分区</p>
<p>​    Set<TopicPartition> assignment = kafkaConsumer.assignment();</p>
<p>​    //对于被分配的分区，全部统一定位到offset=100的位置成为初始偏移量</p>
<p>​    for (TopicPartition topicPartition : assignment) {</p>
<p>​      kafkaConsumer.seek(topicPartition,100);</p>
<p>​    }</p>
<p>​     while (true){</p>
<p>​      ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(Duration.ofMillis(Long.MAX_VALUE));</p>
<p>​      for (ConsumerRecord&lt;String, String&gt; record : records) {</p>
<p>​        // 做一些业务处理</p>
<p>​        System.out.println(record.key() + “,”</p>
<p>​            + record.value() +“,”</p>
<p>​            +record.topic() + “,”</p>
<p>​            +record.partition()+ “,”</p>
<p>​            +record.offset());</p>
<p>​        System.out.println(“----------------------分割线----------------------------”);</p>
<p>​      }</p>
<p>​    }</p>
<p>}</p>
<p>}</p>
<p>（2）运行结果</p>
<img src="/2023/06/20/Kafka/clip_image053.jpg" class="" title="img">
<p>（四）kafka整合</p>
<p>1.kafka+flume</p>
<p>（1）配置flume</p>
<p># define</p>
<p>a1.sources = r1</p>
<p>a1.sinks = k1</p>
<p>a1.channels = c1</p>
<p># source</p>
<p>a1.sources.r1.type = exec</p>
<p>a1.sources.r1.command = tail -F -c +0 /root/flume.log</p>
<p>a1.sources.r1.shell = /bin/bash -c</p>
<p># sink</p>
<p>a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink</p>
<p>a1.sinks.k1.kafka.bootstrap.servers = node1:9092,node2:9092,node3:9092</p>
<p>a1.sinks.k1.kafka.topic = test</p>
<p>a1.sinks.k1.kafka.flumeBatchSize = 20</p>
<p>a1.sinks.k1.kafka.producer.acks = 1</p>
<p><a target="_blank" rel="noopener" href="http://a1.sinks.k1.kafka.producer.linger.ms">a1.sinks.k1.kafka.producer.linger.ms</a> = 1</p>
<p># channel</p>
<p>a1.channels.c1.type = memory</p>
<p>a1.channels.c1.capacity = 1000</p>
<p>a1.channels.c1.transactionCapacity = 100</p>
<p># bind</p>
<p>a1.sources.r1.channels = c1</p>
<p>a1.sinks.k1.channel = c1</p>
<img src="/2023/06/20/Kafka/clip_image055.jpg" class="" title="img">
<p>（2）启动客户端消费者</p>
<p>（3）启动flume</p>
<p>bin/flume-ng agent -c conf/ -n a1 -f myconf/kexample1-flume-jia-kafka.conf</p>
<img src="/2023/06/20/Kafka/clip_image057.jpg" class="" title="img">
<p>（4）向日志中增加数据查看消费情况</p>
<p>1）向flume.log中增加hello world数据</p>
<p>echo hello &gt;&gt; /root/flume.log</p>
<p>echo world &gt;&gt; /root/flume.log</p>
<img src="/2023/06/20/Kafka/clip_image059.jpg" class="" title="img">
<p>2）查看消费的情况</p>
<img src="/2023/06/20/Kafka/clip_image061.jpg" class="" title="img">
<img src="/2023/06/20/Kafka/clip_image063.jpg" class="" title="img">
<p>2.kafka+sparkStreaming</p>
<p>//以workCount 示意：</p>
<p>import org.apache.kafka.clients.consumer.ConsumerRecord</p>
<p>import org.apache.kafka.common.serialization.StringDeserializer</p>
<p>import org.apache.spark.SparkConf</p>
<p>import org.apache.spark.rdd.RDD</p>
<p>import org.apache.spark.streaming.dstream.{DStream, InputDStream}</p>
<p>import org.apache.spark.streaming.kafka010.{ConsumerStrategies, KafkaUtils, LocationStrategies}</p>
<p>import org.apache.spark.streaming.{Seconds, StreamingContext}</p>
<p>object WordCount {</p>
<p>​    def main(args: Array[String]): Unit = {</p>
<p>​       val sparkConf = new SparkConf().setAppName(“spark streaming 整合kafka”).setMaster(“local[*]”)</p>
<p>​</p>
<p>​       val ssc = new StreamingContext(sparkConf, Seconds(1))</p>
<p>​       val kafkaParams = Map[String, Object](</p>
<p>​           “bootstrap.servers” -&gt; “node1:9092,node2:9092,node3:9092”,</p>
<p>​           “key.deserializer” -&gt; classOf[StringDeserializer],</p>
<p>​           “value.deserializer” -&gt; classOf[StringDeserializer],</p>
<p>​           “<a target="_blank" rel="noopener" href="http://group.id">group.id</a>” -&gt; “use_a_separate_group_id_for_each_stream”,</p>
<p>​           “auto.offset.reset” -&gt; “earliest”,</p>
<p>​           “enable.auto.commit” -&gt; (false: java.lang.Boolean)</p>
<p>​           )</p>
<p>​       val topics = Array(“test”)</p>
<p>​       // 获取数据</p>
<p>​       val stream: InputDStream[ConsumerRecord[String, String]] =      KafkaUtils.createDirectStream[String, String](</p>
<p>ssc,</p>
<p>LocationStrategies.PreferConsistent, // 如果计算节点和Broker 是同一台节点可以使用PreferBrokers</p>
<p>ConsumerStrategies.Subscribe[String, String](topics, kafkaParams)</p>
<p>)</p>
<p>​       stream.foreachRDD(rdd =&gt; {</p>
<p>​      val words: RDD[Array[String]] = rdd.map(_.value()).map(line =&gt; line.split(&quot; &quot;))</p>
<p>​           val wordAndOne: RDD[(String, Int)] = words.flatMap(arr =&gt; arr.map(word =&gt; (word, 1)))</p>
<p>​       // RDD[(K, V)]</p>
<p>​           val wordCountResult = wordAndOne.reduceByKey(_ + _)</p>
<p>wordCountResult.foreach(println)</p>
<p>​    })</p>
<p>​    ssc.start()</p>
<p>ssc.awaitTermination()</p>
<p>}</p>
<p>}</p>
<p>（五）kafka原理加强</p>
<p>1.生产者性能测试</p>
<p>（1）tpc_13: 分区数 2,副本数 1</p>
<p><a target="_blank" rel="noopener" href="http://kafka-topics.sh">kafka-topics.sh</a> --create --topic tpc_13 --partitions 2 --replication-factor 1 --zookeeper node1:2181</p>
<img src="/2023/06/20/Kafka/clip_image065.jpg" class="" title="img">
<p><a target="_blank" rel="noopener" href="http://kafka-producer-perf-test.sh">kafka-producer-perf-test.sh</a> --topic tpc_13 --num-records 100 --record-size 1024 --throughput -1 --producer-props bootstrap.servers=node1:9092 acks=1</p>
<img src="/2023/06/20/Kafka/clip_image067.jpg" class="" title="img">
<p>（2）tpc_14: 分区数 2,副本数 2</p>
<p><a target="_blank" rel="noopener" href="http://kafka-topics.sh">kafka-topics.sh</a> --create --topic tpc_14 --partitions 2 --replication-factor 2 --zookeeper node1:2181</p>
<img src="/2023/06/20/Kafka/clip_image069.jpg" class="" title="img">
<p><a target="_blank" rel="noopener" href="http://kafka-producer-perf-test.sh">kafka-producer-perf-test.sh</a> --topic tpc_14 --num-records 100 --record-size 1024 --throughput -1 --producer-props bootstrap.servers=node1:9092 acks=1</p>
<img src="/2023/06/20/Kafka/clip_image071.jpg" class="" title="img">
<p>（3）tpc_15:分区数 3,副本数 1</p>
<p><a target="_blank" rel="noopener" href="http://kafka-topics.sh">kafka-topics.sh</a> --create --topic tpc_15 --partitions 3 --replication-factor 1 --zookeeper node1:2181</p>
<img src="/2023/06/20/Kafka/clip_image073.jpg" class="" title="img">
<p><a target="_blank" rel="noopener" href="http://kafka-producer-perf-test.sh">kafka-producer-perf-test.sh</a> --topic tpc_15 --num-records 100 --record-size 1024 --throughput -1 --producer-props bootstrap.servers=node1:9092 acks=1</p>
<img src="/2023/06/20/Kafka/clip_image075.jpg" class="" title="img">
<p>（4）tpc_16:分区数 6,副本数 1</p>
<p><a target="_blank" rel="noopener" href="http://kafka-topics.sh">kafka-topics.sh</a> --create --topic tpc_16 --partitions 6 --replication-factor 1 --zookeeper node1:2181</p>
<img src="/2023/06/20/Kafka/clip_image077.jpg" class="" title="img">
<p><a target="_blank" rel="noopener" href="http://kafka-producer-perf-test.sh">kafka-producer-perf-test.sh</a> --topic tpc_16 --num-records 100 --record-size 1024 --throughput -1 --producer-props bootstrap.servers=node1:9092 acks=1</p>
<img src="/2023/06/20/Kafka/clip_image079.jpg" class="" title="img">
<p>（5）tpc_22:分区数12</p>
<p><a target="_blank" rel="noopener" href="http://kafka-topics.sh">kafka-topics.sh</a> --create --topic tpc_22 --partitions 12 --replication-factor 1 --zookeeper node1:2181</p>
<img src="/2023/06/20/Kafka/clip_image081.jpg" class="" title="img">
<p><a target="_blank" rel="noopener" href="http://kafka-producer-perf-test.sh">kafka-producer-perf-test.sh</a> --topic tpc_22 --num-records 100 --record-size 1024 --throughput -1 --producer-props bootstrap.servers=node1:9092 acks=1</p>
<img src="/2023/06/20/Kafka/clip_image083.jpg" class="" title="img">
<p>2.按照上方的结果进行可视化分析</p>
<img src="/2023/06/20/Kafka/clip_image085.jpg" class="" title="img">
<p>由上图可以了解到，数据随着分区和副本数的不同产生不同的结果，其中分区数越多，发送速度越快。</p>
<p>3.但是后经过更多分区的测试，可视化线发送速度趋于平稳。</p>
<p>（六）RDD</p>
<p>\1. 初始化执行环境 构建SparkContext对象</p>
<p>from pyspark import SparkConf, SparkContext</p>
<p>if <strong>name</strong> == ‘<strong>main</strong>’:</p>
<p>conf = SparkConf().setAppName(“test”).setMaster(“local[*]”)</p>
<p>sc = SparkContext(conf=conf)</p>
<p>rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9])</p>
<p>print(&quot;默认分区数: &quot;, rdd.getNumPartitions())</p>
<p>rdd = sc.parallelize([1, 2, 3], 3)</p>
<p>print(&quot;分区数: &quot;, rdd.getNumPartitions())</p>
<p>print(&quot;rdd的内容是: &quot;, rdd.collect())</p>
<img src="/2023/06/20/Kafka/clip_image087.jpg" class="" title="img">
<p>2.数据分区处理并读取</p>
<p>from pyspark import SparkConf, SparkContext</p>
<p>if <strong>name</strong> == ‘<strong>main</strong>’:</p>
<p>conf = SparkConf().setAppName(“test”).setMaster(“local[*]”)</p>
<p>sc = SparkContext(conf=conf)</p>
<p>file_rdd1 = sc.textFile(“…/data/input/words.txt”)</p>
<p>print(&quot;默认读取分区数: &quot;, file_rdd1.getNumPartitions())</p>
<p>print(“file_rdd1 内容:”, file_rdd1.collect())</p>
<p>file_rdd2 = sc.textFile(“…/data/input/words.txt”, 3)</p>
<p>file_rdd3 = sc.textFile(“…/data/input/words.txt”, 100)</p>
<p>print(“file_rdd2 分区数:”, file_rdd2.getNumPartitions())</p>
<p>print(“file_rdd3 分区数:”, file_rdd3.getNumPartitions())</p>
<p>hdfs_rdd = sc.textFile(“hdfs://node1:8020/input/words.txt”)</p>
<p>print(“hdfs_rdd 内容:”, hdfs_rdd.collect())</p>
<p>创建本地文件words.txt，上传文件words.txt到hdfs上</p>
<img src="/2023/06/20/Kafka/clip_image089.jpg" class="" title="img">
<img src="/2023/06/20/Kafka/clip_image091.jpg" class="" title="img">

	</div>
</article>



    </div>
  </div>
  <div class="row">
<div id="bottom" class="col-md-12"> 
  <div class="bottom-nav">
	
	
	<a href="https://github.com/lizehongss" class="fa fa-github fa-2x" target="_blank" title="Follow me" ></a>
	
	
</div>
<div class="bottom-info">
	&copy; 2023 John Doe<br>
	Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
	theme <a href="https://github.com/lizehongss/hexo-theme-zhl" target="_blank">zhl</a>
</div>
</div>
</div>
</div>
<div id="tool">
  <ul>
    <li class="fa fa-angle-up top" id="top"></li>
  </ul>
</div>
  <div class="bg_content">
    <canvas id="canvas"></canvas>
  </div>
  
  <!-- scripts list from theme config.yml -->
  
    <script src="/js/zhl.js"></script>
  
    <script src="/js/bj.js"></script>
  

<!-- jQ cdn  -->
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<!-- bootstrap js cdn-->
<!-- <script src="https://cdn.bootcss.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script> -->


</body>
</html>
